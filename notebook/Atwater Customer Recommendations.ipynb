{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atwater Customer Recommendations\n",
    "\n",
    "#### A demo using DataStax Enterprise Analytics, Apache Cassandra, Apache Spark, python and Jupyter Notebooks to utilize the power of big customer data to recommend items to our customers with a high degree of accruacy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things To Setup\n",
    "* Install DSE https://docs.datastax.com/en/install/doc/install60/installTOC.html\n",
    "* Start DSE Analytics Cluster\n",
    "* Using Python 2.7\n",
    "* Using DSE Analytics 6\n",
    "* Using latest verion of Jupyter \n",
    "* Find full path to <>/lib/pyspark.zip\n",
    "* Find full path to <>/lib/py4j-0.10.4-src.zip\n",
    "* Start Jupyter with DSE to get all environemnt variables: dse exec jupyter notebook\n",
    "* Make sure that the two CSV files are in the same locations as this notebook\n",
    "* !pip install cassandra-driver\n",
    "* !pip install pattern \n",
    "* !pip install panadas\n",
    "* Counter-intuitive don't install pyspark!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add some environment variables to find dse verision of pyspark. Edit these varibles with your path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pysparkzip = \"/usr/share/dse/spark/python/lib/pyspark.zip\"\n",
    "py4jzip = \"/usr/share/dse/spark/python/lib/py4j-0.10.4-src.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed to be able to find pyspark libaries\n",
    "import sys\n",
    "sys.path.append(pysparkzip)\n",
    "sys.path.append(py4jzip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import python packages -- all are required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import cassandra\n",
    "import pyspark\n",
    "import re\n",
    "import os\n",
    "from IPython.display import display, Markdown\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer, StopWordsRemover\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pattern.en import sentiment, positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper function to have nicer formatting of Spark DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper for pretty formatting for Spark DataFrames\n",
    "def showDF(df, limitRows =  5, truncate = True):\n",
    "    if(truncate):\n",
    "        pandas.set_option('display.max_colwidth', 50)\n",
    "    else:\n",
    "        pandas.set_option('display.max_colwidth', -1)\n",
    "    pandas.set_option('display.max_rows', limitRows)\n",
    "    display(df.limit(limitRows).toPandas())\n",
    "    pandas.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Tables, Pulling Tweets, and Loading Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connect to DSE Analytics Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cassandra.cluster import Cluster\n",
    "\n",
    "cluster = Cluster(['127.0.0.1']) #If you have a locally installed DSE cluster\n",
    "session = cluster.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Demo Keyspace "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7f36241ecbd0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.execute(\"\"\"\n",
    "    CREATE KEYSPACE IF NOT EXISTS demo \n",
    "    WITH REPLICATION = \n",
    "    { 'class' : 'SimpleStrategy', 'replication_factor' : 1 }\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set keyspace "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.set_keyspace('demo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the customer transaction table in DSE. Our primary key will be on customer id and state, and our clustering columns will be around gender, age, and rewards member status. Consider your data model when choosing your primary key. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x6d92e50>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"CREATE TABLE IF NOT EXISTS customer_transactions (id int, \\\n",
    "                                                            customer_name text, \\\n",
    "                                                            gender text, age int, \\\n",
    "                                                            state text, home_store int, \\\n",
    "                                                            items list<text>, year int, \\\n",
    "                                                            month int, rewards_member text, \\\n",
    "                                                            PRIMARY KEY ((id, state), gender, age))\"\n",
    "session.execute(query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Testing Data from CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x6d87c90>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"CREATE TABLE IF NOT EXISTS customer_test (id int, \\\n",
    "                                                            customer_name text, \\\n",
    "                                                            gender text, age int, \\\n",
    "                                                            state text, home_store int, \\\n",
    "                                                            items list<text>, year int, \\\n",
    "                                                            month int, rewards_member text, \\\n",
    "                                                            PRIMARY KEY ((id, state), gender, age))\"\n",
    "session.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7d01510>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"CREATE TABLE IF NOT EXISTS customer_recommend (id int, \\\n",
    "                                                            customer_name text, \\\n",
    "                                                            gender text, age int, \\\n",
    "                                                            state text, home_store int, \\\n",
    "                                                            items list<text>, year int, \\\n",
    "                                                            month int, rewards_member text,\\\n",
    "                                                            prediction list<text>,\\\n",
    "                                                            PRIMARY KEY ((id, state), gender, age))\"\n",
    "session.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 3 child processes\n",
      "\n",
      "Starting copy of demo.customer_transactions with columns [id, customer_name, gender, age, state, home_store, items, year, month, rewards_member].\n",
      "loadCustomer.cql:2:Failed to import 1 rows: ParseError - Invalid row length 0 should be 10,  given up without retries\n",
      "loadCustomer.cql:2:Failed to process 1 rows; failed rows written to import_demo_customer_transactions.err\n",
      "Processed: 3 rows; Rate:       5 rows/s; Avg. rate:       7 rows/s\n",
      "3 rows imported from 1 files in 0.426 seconds (0 skipped).\n",
      "Using 3 child processes\n",
      "\n",
      "Starting copy of demo.customer_test with columns [id, customer_name, gender, age, state, home_store, items, year, month, rewards_member].\n",
      "Processed: 1 rows; Rate:       3 rows/s; Avg. rate:       3 rows/sProcessed: 1 rows; Rate:       2 rows/s; Avg. rate:       3 rows/s\n",
      "1 rows imported from 1 files in 0.389 seconds (0 skipped).\n"
     ]
    }
   ],
   "source": [
    "!cqlsh -f loadCustomer.cql\n",
    "!cqlsh -f loadCustomerTest.cql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do a select * on each table and verify that the tweets have been inserted into each Cassandra table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, [u'Collar', u'Bed', u'Bowl'])\n",
      "(1, [u'Collar', u'Sweater', u'Bed'])\n"
     ]
    }
   ],
   "source": [
    "query = 'SELECT * FROM customer_transactions limit 10'\n",
    "rows = session.execute(query)\n",
    "for user_row in rows:\n",
    "    print (user_row.id, user_row.items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally time for Apache Spark! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a spark session that is connected to Cassandra. From there load each table into a Spark Dataframe and take a count of the number of rows in each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table Train Count: \n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>state</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>customer_name</th>\n",
       "      <th>home_store</th>\n",
       "      <th>items</th>\n",
       "      <th>month</th>\n",
       "      <th>rewards_member</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>CA</td>\n",
       "      <td>M</td>\n",
       "      <td>7</td>\n",
       "      <td>Rocky Bucaojit</td>\n",
       "      <td>21</td>\n",
       "      <td>[Collar, Bed, Bowl]</td>\n",
       "      <td>11</td>\n",
       "      <td>N</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CA</td>\n",
       "      <td>M</td>\n",
       "      <td>14</td>\n",
       "      <td>Toby Moran</td>\n",
       "      <td>20</td>\n",
       "      <td>[Collar, Sweater, Bed]</td>\n",
       "      <td>12</td>\n",
       "      <td>N</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id state gender  age   customer_name  home_store                   items  \\\n",
       "0   2    CA      M    7  Rocky Bucaojit          21     [Collar, Bed, Bowl]   \n",
       "1   1    CA      M   14      Toby Moran          20  [Collar, Sweater, Bed]   \n",
       "\n",
       "   month rewards_member  year  \n",
       "0     11              N  2014  \n",
       "1     12              N  2014  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table Test Count: \n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>state</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>customer_name</th>\n",
       "      <th>home_store</th>\n",
       "      <th>items</th>\n",
       "      <th>month</th>\n",
       "      <th>rewards_member</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>CA</td>\n",
       "      <td>M</td>\n",
       "      <td>7</td>\n",
       "      <td>Max Moran</td>\n",
       "      <td>24</td>\n",
       "      <td>[Bed]</td>\n",
       "      <td>2</td>\n",
       "      <td>Y</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id state gender  age customer_name  home_store  items  month  \\\n",
       "0   3    CA      M    7     Max Moran          24  [Bed]      2   \n",
       "\n",
       "  rewards_member  year  \n",
       "0              Y  2015  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('demo').master(\"local\").getOrCreate()\n",
    "\n",
    "tableDF = spark.read.format(\"org.apache.spark.sql.cassandra\").options(table=\"customer_transactions\", keyspace=\"demo\").load()\n",
    "\n",
    "testDF = spark.read.format(\"org.apache.spark.sql.cassandra\").options(table=\"customer_test\", keyspace=\"demo\").load()\n",
    "\n",
    "\n",
    "print \"Table Train Count: \"\n",
    "print tableDF.count()\n",
    "showDF(tableDF)\n",
    "\n",
    "print \"Table Test Count: \"\n",
    "print testDF.count()\n",
    "showDF(testDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use FPGrowth to find Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+------+---+-------------+----------+-----+-----+--------------+----+----------+\n",
      "| id|state|gender|age|customer_name|home_store|items|month|rewards_member|year|prediction|\n",
      "+---+-----+------+---+-------------+----------+-----+-----+--------------+----+----------+\n",
      "|  3|   CA|     M|  7|    Max Moran|        24|[Bed]|    2|             Y|2015|  [Collar]|\n",
      "+---+-----+------+---+-------------+----------+-----+-----+--------------+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.fpm import FPGrowth\n",
    "\n",
    "fpGrowth = FPGrowth(itemsCol=\"items\", minSupport=0.5, minConfidence=0.6)\n",
    "model = fpGrowth.fit(tableDF)\n",
    "recommendDF=model.transform(testDF)\n",
    "recommendDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendDF.write.format(\"org.apache.spark.sql.cassandra\").options(table=\"customer_recommend\", keyspace=\"demo\").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, [u'Bed'], [u'Collar'])\n"
     ]
    }
   ],
   "source": [
    "query = 'SELECT * FROM customer_recommend limit 10'\n",
    "rows = session.execute(query)\n",
    "for user_row in rows:\n",
    "    print (user_row.id, user_row.items, user_row.prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
