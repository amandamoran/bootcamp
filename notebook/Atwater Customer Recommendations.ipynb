{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atwater Customer Recommendations\n",
    "\n",
    "#### A demo using DataStax Enterprise Analytics, Apache Cassandra, Apache Spark, Python and Jupyter Notebooks to utilize the power of big customer data to recommend items to our customers with a high degree of accruacy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things To Setup\n",
    "* Install DSE https://docs.datastax.com/en/install/doc/install60/installTOC.html\n",
    "* Start DSE Analytics Cluster\n",
    "* Using Python 2.7\n",
    "* Using DSE Analytics 6\n",
    "* Using latest verion of Jupyter \n",
    "* Find full path to <>/lib/pyspark.zip\n",
    "* Find full path to <>/lib/py4j-0.10.4-src.zip\n",
    "* Start Jupyter with DSE to get all environemnt variables: dse exec jupyter notebook\n",
    "* Make sure that the two CSV files are in the same locations as this notebook\n",
    "* !pip install cassandra-driver\n",
    "* !pip install pattern \n",
    "* !pip install panadas\n",
    "* Counter-intuitive don't install pyspark!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add some environment variables to find dse verision of pyspark. Edit these varibles with your path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pysparkzip = \"/usr/share/dse/spark/python/lib/pyspark.zip\"\n",
    "py4jzip = \"/usr/share/dse/spark/python/lib/py4j-0.10.4-src.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed to be able to find pyspark libaries\n",
    "import sys\n",
    "sys.path.append(pysparkzip)\n",
    "sys.path.append(py4jzip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import python packages -- all are required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import cassandra\n",
    "import pyspark\n",
    "import re\n",
    "import os\n",
    "from IPython.display import display, Markdown\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer, StopWordsRemover\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pattern.en import sentiment, positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper function to have nicer formatting of Spark DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper for pretty formatting for Spark DataFrames\n",
    "def showDF(df, limitRows =  5, truncate = True):\n",
    "    if(truncate):\n",
    "        pandas.set_option('display.max_colwidth', 50)\n",
    "    else:\n",
    "        pandas.set_option('display.max_colwidth', -1)\n",
    "    pandas.set_option('display.max_rows', limitRows)\n",
    "    display(df.limit(limitRows).toPandas())\n",
    "    pandas.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Tables, Pulling Tweets, and Loading Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connect to DSE Analytics Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cassandra.cluster import Cluster\n",
    "\n",
    "cluster = Cluster(['127.0.0.1']) #If you have a locally installed DSE cluster\n",
    "session = cluster.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Demo Keyspace --Replication Factor is 1 since only have a one node demo cluster. Replication Factor is recommended at 3 or Write Consistency + Read Consistency > Replication Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7bbdc10>"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.execute(\"\"\"\n",
    "    CREATE KEYSPACE IF NOT EXISTS demo \n",
    "    WITH REPLICATION = \n",
    "    { 'class' : 'SimpleStrategy', 'replication_factor' : 1 }\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set keyspace "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.set_keyspace('demo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the customer transaction table in DSE (this is for completed transactions).  This table will be updated with about 1000 transactions a minute (Atwater has around 200,000 transactions a day on their website)\n",
    "#### Our primary key will be on state (limiting our analysis to just the US), and our clustering columns will be around gender, age and the transaction id. Consider your data model when choosing your primary key. This will give us a good distriubtion of the data and a unique row for each transaction. We will also be able to create models around age, gender, and state to give the best possible recommendations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7c07b90>"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"CREATE TABLE IF NOT EXISTS customer_transactions (id int, \\\n",
    "                                                            customer_name text, \\\n",
    "                                                            gender text, age int, \\\n",
    "                                                            state text, home_store int, \\\n",
    "                                                            items list<text>, year int, \\\n",
    "                                                            month int, rewards_member text, \\\n",
    "                                                            PRIMARY KEY ((state), gender, age, id))\"\n",
    "session.execute(query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the live customer table in DSE - this represents live customers that are currently logged in on the site and what they have in their shopping cart. \n",
    "#### We will use that information to get a prediction of what we should recommend for them.  The data model is the same as above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7bf2090>"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"CREATE TABLE IF NOT EXISTS customer_live (id int, \\\n",
    "                                                            customer_name text, \\\n",
    "                                                            gender text, age int, \\\n",
    "                                                            state text, home_store int, \\\n",
    "                                                            items list<text>, year int, \\\n",
    "                                                            month int, rewards_member text, \\\n",
    "                                                            PRIMARY KEY ((state), gender, age, id))\"\n",
    "session.execute(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Customer Recommendation Table in DSE\n",
    "#### This table will be used with the inventory table to show the correct, in-stock items by the website. --In reality this information probably would not be written back to a Cassandra table as it doesn't need to be stored long-term. For the shake of the demo showing fast reads and fast writes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7c1f810>"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"CREATE TABLE IF NOT EXISTS customer_recommend (id int, \\\n",
    "                                                            customer_name text, \\\n",
    "                                                            gender text, age int, \\\n",
    "                                                            state text, home_store int, \\\n",
    "                                                            items list<text>, year int, \\\n",
    "                                                            month int, rewards_member text,\\\n",
    "                                                            prediction list<text>,\\\n",
    "                                                            PRIMARY KEY ((id, state), gender, age))\"\n",
    "session.execute(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Inventory Table in DSE \n",
    "#### Our primary key is going to be around the item type (pants, shirts, blender), the location of the items, the sku, and if it the items is currently avaliable. While customers may want to look at items that are on back-order, we do not want to recommend them. This will only cause frustration. This table would have around 6 million entries at one time, with inserts/deletions daily. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7c6f150>"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"CREATE TABLE IF NOT EXISTS inventory (sku int, \\\n",
    "                                               item_name text, item_type text, \\\n",
    "                                               stock_loc text, num_items int, \\\n",
    "                                               backorder text, \\\n",
    "                                               PRIMARY KEY (item_type, stock_loc, sku, backorder))\"\n",
    "session.execute(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load CSV files into DSE for Customer Transactions, Customer Live/Shopping Cart and Inventory Tables\n",
    "##### Note could also use bulk loader or a loop with insert statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1|Toby Moran|M|14|CA|20|['Collar','Sweater','Bed']|2014|12|N\n",
      "2|Rocky Bucaojit|M|7|CA|21|['Collar', 'Bed', 'Bowl']|2014|11|N\n",
      "COPY demo.customer_transactions( id, customer_name, gender, age, state, home_store, items, year, month, rewards_member) FROM 'customer.csv' WITH DELIMITER = '|';\n",
      "Using 3 child processes\n",
      "\n",
      "Starting copy of demo.customer_transactions with columns [id, customer_name, gender, age, state, home_store, items, year, month, rewards_member].\n",
      "loadCustomer.cql:2:Failed to import 1 rows: ParseError - Invalid row length 0 should be 10,  given up without retries\n",
      "loadCustomer.cql:2:Failed to process 1 rows; failed rows written to import_demo_customer_transactions.err\n",
      "Processed: 3 rows; Rate:       5 rows/s; Avg. rate:       7 rows/s\n",
      "3 rows imported from 1 files in 0.406 seconds (0 skipped).\n"
     ]
    }
   ],
   "source": [
    "!head -n 2 customer.csv\n",
    "!cat loadCustomer.cql\n",
    "!cqlsh -f loadCustomer.cql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3|Max Moran|M|7|CA|24|['Bed']|2015|02|Y\n",
      "COPY demo.customer_live( id, customer_name, gender, age, state, home_store, items, year, month, rewards_member) FROM 'customerTest.csv' WITH DELIMITER = '|';\n",
      "Using 3 child processes\n",
      "\n",
      "Starting copy of demo.customer_live with columns [id, customer_name, gender, age, state, home_store, items, year, month, rewards_member].\n",
      "Processed: 1 rows; Rate:       3 rows/s; Avg. rate:       3 rows/sProcessed: 1 rows; Rate:       2 rows/s; Avg. rate:       3 rows/s\n",
      "1 rows imported from 1 files in 0.388 seconds (0 skipped).\n"
     ]
    }
   ],
   "source": [
    "!head -n 2 customerTest.csv\n",
    "!cat loadCustomerTest.cql\n",
    "!cqlsh -f loadCustomerTest.cql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1|Fancy Collar 1|Collar|CA|5|N\n",
      "2|Fancy Collar 2|Collar|CA|0|Y\n",
      "COPY demo.inventory( sku, item_name, item_type, stock_loc, num_items, backorder) FROM 'inventory.csv' WITH DELIMITER = '|';\n",
      "Using 3 child processes\n",
      "\n",
      "Starting copy of demo.inventory with columns [sku, item_name, item_type, stock_loc, num_items, backorder].\n",
      "Processed: 3 rows; Rate:      10 rows/s; Avg. rate:      10 rows/sProcessed: 3 rows; Rate:       5 rows/s; Avg. rate:       8 rows/s\n",
      "3 rows imported from 1 files in 0.398 seconds (0 skipped).\n"
     ]
    }
   ],
   "source": [
    "!head -n 2 inventory.csv\n",
    "!cat loadInventory.cql\n",
    "!cqlsh -f loadInventory.cql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do a select * on customer transaction table and verify that the values have been inserted into the DSE table. Because we have used as our primary key \"State\" we can use this in our WHERE clause."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT * FROM customer_transactions WHERE state='CA' limit 10\n",
      "(2, [u'Collar', u'Bed', u'Bowl'])\n",
      "(1, [u'Collar', u'Sweater', u'Bed'])\n"
     ]
    }
   ],
   "source": [
    "query = 'SELECT * FROM customer_transactions WHERE state=\\'CA\\' limit 10'\n",
    "rows = session.execute(query)\n",
    "for user_row in rows:\n",
    "    print (user_row.id, user_row.items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally time for Some Analytics!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a spark session that is connected to Cassandra. From there load each table into a Spark Dataframe and take a count of the number of rows in each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table Train Count: \n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>id</th>\n",
       "      <th>customer_name</th>\n",
       "      <th>home_store</th>\n",
       "      <th>items</th>\n",
       "      <th>month</th>\n",
       "      <th>rewards_member</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CA</td>\n",
       "      <td>M</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>Rocky Bucaojit</td>\n",
       "      <td>21</td>\n",
       "      <td>[Collar, Bed, Bowl]</td>\n",
       "      <td>11</td>\n",
       "      <td>N</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CA</td>\n",
       "      <td>M</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>Toby Moran</td>\n",
       "      <td>20</td>\n",
       "      <td>[Collar, Sweater, Bed]</td>\n",
       "      <td>12</td>\n",
       "      <td>N</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state gender  age  id   customer_name  home_store                   items  \\\n",
       "0    CA      M    7   2  Rocky Bucaojit          21     [Collar, Bed, Bowl]   \n",
       "1    CA      M   14   1      Toby Moran          20  [Collar, Sweater, Bed]   \n",
       "\n",
       "   month rewards_member  year  \n",
       "0     11              N  2014  \n",
       "1     12              N  2014  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table Test Count: \n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>id</th>\n",
       "      <th>customer_name</th>\n",
       "      <th>home_store</th>\n",
       "      <th>items</th>\n",
       "      <th>month</th>\n",
       "      <th>rewards_member</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CA</td>\n",
       "      <td>M</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>Max Moran</td>\n",
       "      <td>24</td>\n",
       "      <td>[Bed]</td>\n",
       "      <td>2</td>\n",
       "      <td>Y</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state gender  age  id customer_name  home_store  items  month  \\\n",
       "0    CA      M    7   3     Max Moran          24  [Bed]      2   \n",
       "\n",
       "  rewards_member  year  \n",
       "0              Y  2015  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('demo').master(\"local\").getOrCreate()\n",
    "\n",
    "tableDF = spark.read.format(\"org.apache.spark.sql.cassandra\").options(table=\"customer_transactions\", keyspace=\"demo\").load()\n",
    "\n",
    "testDF = spark.read.format(\"org.apache.spark.sql.cassandra\").options(table=\"customer_live\", keyspace=\"demo\").load()\n",
    "\n",
    "\n",
    "print \"Table Train Count: \"\n",
    "print tableDF.count()\n",
    "showDF(tableDF)\n",
    "\n",
    "print \"Table Test Count: \"\n",
    "print testDF.count()\n",
    "showDF(testDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use FPGrowth to find Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---+---+-------------+----------+-----+-----+--------------+----+----------+\n",
      "|state|gender|age| id|customer_name|home_store|items|month|rewards_member|year|prediction|\n",
      "+-----+------+---+---+-------------+----------+-----+-----+--------------+----+----------+\n",
      "|   CA|     M|  7|  3|    Max Moran|        24|[Bed]|    2|             Y|2015|  [Collar]|\n",
      "+-----+------+---+---+-------------+----------+-----+-----+--------------+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.fpm import FPGrowth\n",
    "\n",
    "fpGrowth = FPGrowth(itemsCol=\"items\", minSupport=0.5, minConfidence=0.6)\n",
    "model = fpGrowth.fit(tableDF)\n",
    "recommendDF=model.transform(testDF)\n",
    "recommendDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendDF.write.format(\"org.apache.spark.sql.cassandra\").options(table=\"customer_recommend\", keyspace=\"demo\").save(mode=\"append\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer: Max Moran **Shopping Cart: [u'Bed']** --> Current Recommendations: Fancy Collar 1\n",
      "Customer: Max Moran **Shopping Cart: [u'Bed']** --> Current Recommendations: Fancy Collar 2\n"
     ]
    }
   ],
   "source": [
    "query = 'SELECT * FROM customer_recommend limit 10'\n",
    "rows = session.execute(query)\n",
    "for user_row in rows:\n",
    "    for item in user_row.prediction:\n",
    "        query = \"SELECT * FROM inventory WHERE item_type=\\'%s\\' AND stock_loc=\\'%s\\'\" % (item, user_row.state)\n",
    "        items = session.execute(query)\n",
    "        for item_row in items:\n",
    "            print \"Customer: \" + user_row.customer_name + \" **Shopping Cart: \" + str(user_row.items) + \"** --> Current Recommendations: \" + item_row.item_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
